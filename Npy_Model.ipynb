{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4d0d3-848b-4939-8f0e-89f90f1f11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2e430-4489-414a-aa30-ba9979cf0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_file_lists(image_dir, landmark_dir):\n",
    "    real_image_files = glob.glob(os.path.join(image_dir, 'Real', '*.jpg')) + \\\n",
    "                       glob.glob(os.path.join(image_dir, 'real', '*.jpg'))\n",
    "    fake_image_files = glob.glob(os.path.join(image_dir, 'Fake', '*.jpg')) + \\\n",
    "                       glob.glob(os.path.join(image_dir, 'fake', '*.jpg'))\n",
    "\n",
    "    # Prepare corresponding landmark file paths\n",
    "    real_landmark_files = [\n",
    "        os.path.join(landmark_dir, 'real', os.path.basename(f).replace('.jpg', '_landmarks.npy'))\n",
    "        for f in real_image_files\n",
    "    ]\n",
    "    fake_landmark_files = [\n",
    "        os.path.join(landmark_dir, 'fake', os.path.basename(f).replace('.jpg', '_landmarks.npy'))\n",
    "        for f in fake_image_files\n",
    "    ]\n",
    "\n",
    "    # Filter out images without landmarks\n",
    "    real_pairs = [\n",
    "        (img, lm) for img, lm in zip(real_image_files, real_landmark_files) if os.path.exists(lm)\n",
    "    ]\n",
    "    fake_pairs = [\n",
    "        (img, lm) for img, lm in zip(fake_image_files, fake_landmark_files) if os.path.exists(lm)\n",
    "    ]\n",
    "\n",
    "    # Unzip the pairs\n",
    "    if real_pairs:\n",
    "        real_image_files, real_landmark_files = zip(*real_pairs)\n",
    "    else:\n",
    "        real_image_files, real_landmark_files = [], []\n",
    "\n",
    "    if fake_pairs:\n",
    "        fake_image_files, fake_landmark_files = zip(*fake_pairs)\n",
    "    else:\n",
    "        fake_image_files, fake_landmark_files = [], []\n",
    "\n",
    "    # Combine real and fake\n",
    "    image_files = list(real_image_files) + list(fake_image_files)\n",
    "    landmark_files = list(real_landmark_files) + list(fake_landmark_files)\n",
    "    labels = [0] * len(real_image_files) + [1] * len(fake_image_files)  # 0 for real, 1 for fake\n",
    "\n",
    "    # Shuffle the data\n",
    "    image_files, landmark_files, labels = shuffle(image_files, landmark_files, labels, random_state=42)\n",
    "\n",
    "    return image_files, landmark_files, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f25471-2913-4f85-b1e7-d05be3da6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where your dataset is stored\n",
    "base_dir = '/kaggle/working/dataset-600k'  # Update with your actual path\n",
    "\n",
    "# Training data\n",
    "train_image_dir = os.path.join(base_dir, 'Train')\n",
    "train_landmark_dir = os.path.join(base_dir, 'Train_Landmark')\n",
    "\n",
    "# Validation data\n",
    "val_image_dir = os.path.join(base_dir, 'Validation')\n",
    "val_landmark_dir = os.path.join(base_dir, 'Validation_Landmark')\n",
    "\n",
    "# Testing data\n",
    "test_image_dir = os.path.join(base_dir, 'Test')\n",
    "test_landmark_dir = os.path.join(base_dir, 'Test_Landmark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c5ab3-ebbd-4c79-809c-786d3688c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "train_image_files, train_landmark_files, train_labels = prepare_file_lists(train_image_dir, train_landmark_dir)\n",
    "\n",
    "# Prepare validation data\n",
    "val_image_files, val_landmark_files, val_labels = prepare_file_lists(val_image_dir, val_landmark_dir)\n",
    "\n",
    "# Prepare testing data\n",
    "test_image_files, test_landmark_files, test_labels = prepare_file_lists(test_image_dir, test_landmark_dir)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_image_files)}\")\n",
    "print(f\"Number of validation samples: {len(val_image_files)}\")\n",
    "print(f\"Number of testing samples: {len(test_image_files)}\")\n",
    "\n",
    "# Optionally, print some file paths to verify\n",
    "print(\"Sample training image:\", train_image_files[0] if train_image_files else \"No training images\")\n",
    "print(\"Sample training landmark:\", train_landmark_files[0] if train_landmark_files else \"No training landmarks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b3784-0810-4845-bfed-1df15683ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, image_files, landmark_files, labels, batch_size, image_size, shuffle=True, augment=False):\n",
    "        self.image_files = image_files\n",
    "        self.landmark_files = landmark_files\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size  # Tuple (height, width)\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        # Define Albumentations augmentation pipeline\n",
    "        if self.augment:\n",
    "            self.augmentation_pipeline = A.Compose([\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.2),\n",
    "                A.RandomBrightnessContrast(p=0.5),\n",
    "                A.Rotate(limit=30, p=0.5),\n",
    "                A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
    "                A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "                A.MotionBlur(blur_limit=5, p=0.5),\n",
    "                A.CLAHE(clip_limit=4.0, p=0.5),\n",
    "                A.RandomResizedCrop(height=self.image_size[0], width=self.image_size[1], scale=(0.6, 1.0), p=0.5),\n",
    "            ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "        else:\n",
    "            self.augmentation_pipeline = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_files) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_image_files = self.image_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_landmark_files = self.landmark_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        images = []\n",
    "        landmarks = []\n",
    "        labels = []\n",
    "        \n",
    "        for img_file, lm_file, label in zip(batch_image_files, batch_landmark_files, batch_labels):\n",
    "            try:\n",
    "                # Load image\n",
    "                img = load_img(img_file, target_size=self.image_size)\n",
    "                img = np.array(img)  # Convert to NumPy array (RGB format)\n",
    "                \n",
    "                # Load landmarks\n",
    "                lm = np.load(lm_file).astype('float32')  # Shape: (68, 2)\n",
    "                \n",
    "                # Adjust landmarks\n",
    "                lm[:, 0] *= (self.image_size[1] / img.shape[1])\n",
    "                lm[:, 1] *= (self.image_size[0] / img.shape[0])\n",
    "                \n",
    "                # Apply augmentation if enabled\n",
    "                if self.augment and self.augmentation_pipeline:\n",
    "                    augmented = self.augmentation_pipeline(image=img, keypoints=lm)\n",
    "                    img = augmented['image']\n",
    "                    lm = np.array(augmented['keypoints'])\n",
    "                \n",
    "                # Ensure image is float32 before preprocessing\n",
    "                img = img.astype('float32')\n",
    "                \n",
    "                # Apply model-specific preprocessing\n",
    "                img = preprocess_input(img)\n",
    "                \n",
    "                # Normalize landmarks relative to image size\n",
    "                lm[:, 0] /= self.image_size[1]\n",
    "                lm[:, 1] /= self.image_size[0]\n",
    "                lm = lm.flatten()\n",
    "                \n",
    "                images.append(img)\n",
    "                landmarks.append(lm)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_file} and {lm_file}: {e}\")\n",
    "                continue  # Skip to the next item\n",
    "        \n",
    "        # Convert lists to arrays\n",
    "        images_array = np.array(images)\n",
    "        landmarks_array = np.array(landmarks)\n",
    "        labels_array = np.array(labels)\n",
    "        \n",
    "        return {'image_input': images_array, 'landmark_input': landmarks_array}, labels_array\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.image_files, self.landmark_files, self.labels))\n",
    "            np.random.shuffle(temp)\n",
    "            self.image_files, self.landmark_files, self.labels = zip(*temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51cf06c-393e-4672-8dac-5124e8a2eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = (360, 360)  # Updated image resolution\n",
    "\n",
    "# Training generator with augmentation\n",
    "train_generator = DataGenerator(\n",
    "    train_image_files,\n",
    "    train_landmark_files,\n",
    "    train_labels,\n",
    "    batch_size,\n",
    "    image_size,\n",
    "    shuffle=True,\n",
    "    augment=True  # Enable augmentation for training\n",
    ")\n",
    "\n",
    "# Validation generator without augmentation\n",
    "val_generator = DataGenerator(\n",
    "    val_image_files,\n",
    "    val_landmark_files,\n",
    "    val_labels,\n",
    "    batch_size,\n",
    "    image_size,\n",
    "    shuffle=False,\n",
    "    augment=False  # No augmentation for validation\n",
    ")\n",
    "\n",
    "# Testing generator without augmentation\n",
    "test_generator = DataGenerator(\n",
    "    test_image_files,\n",
    "    test_landmark_files,\n",
    "    test_labels,\n",
    "    batch_size,\n",
    "    image_size,\n",
    "    shuffle=False,\n",
    "    augment=False  # No augmentation for testing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b0b9c-7ef8-46d3-a1c3-adcd9c008309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Input Branch\n",
    "image_input = Input(shape=(image_size[0], image_size[1], 3), name='image_input')\n",
    "landmark_input = Input(shape=(136,), name='landmark_input')\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=image_input)\n",
    "\n",
    "# Optionally unfreeze last N layers\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "x_image = base_model.output\n",
    "x_image = GlobalAveragePooling2D()(x_image)\n",
    "x_image = Dense(512, activation='relu', kernel_regularizer=l2(1e-3))(x_image)\n",
    "x_image = Dropout(0.6)(x_image)\n",
    "\n",
    "# Landmark Input Branch\n",
    "x_landmark = Dense(256, activation='relu', kernel_regularizer=l2(1e-4))(landmark_input)\n",
    "x_landmark = Dropout(0.5)(x_landmark)\n",
    "x_landmark = Dense(128, activation='relu', kernel_regularizer=l2(1e-4))(x_landmark)\n",
    "x_landmark = Dropout(0.5)(x_landmark)\n",
    "\n",
    "# Combine Features\n",
    "combined = Concatenate()([x_image, x_landmark])\n",
    "\n",
    "# Fully Connected Layers\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(1e-4))(combined)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output Layer\n",
    "output = Dense(1, activation='sigmoid')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e9953-e2e5-4e0a-94c0-2611208afbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model\n",
    "model = Model(inputs=[image_input, landmark_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65661f37-cd82-4f23-a5d4-a91a2b9df0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c2dbd-f06b-4ae5-929d-747f2b98660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44908b-4735-417f-8ebd-4ed3461db7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_auc',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=3,  # Reduced patience as per your previous code\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,  # Reduced patience\n",
    "    verbose=1,\n",
    "    min_lr=1e-7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4986e26-59d4-43c7-a1ae-8a29cccfdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
